<!DOCTYPE html>
<html>
<head>
  <title>Python Code</title>
</head>
<body>
  <pre>
    <code>
      import torch
      import matplotlib.pyplot as plt
      import numpy as np
      import torch.nn as nn
      import torchvision
      import torchvision.transforms as transforms

      # tensors used as indices
      batch_size = 10
      num_class = 2
      x = torch.randn([batch_size, num_class])
      print(f'original x {x}')
      x_index = torch.arange(batch_size)
      print(f'x_index{x_index}')
      original_y = torch.arange(num_class)
      y = torch.tensor([], dtype=torch.float)
      for i in range(5):
          y = torch.concatenate([y, original_y], dim=0)
      print(f' y {y}')
      target_score = x[x_index, y]
      print(target_score)

      # broadcast trick
      print(X_train[0])
      matrix = []
      for i in range(test_size):
          row = []
          for j in range(train_size):
              temp = X_test[i] - X_train[j]
              res = torch.sum(torch.square(temp))
              row.append(res)
              matrix.append(row)
      for i in range(10):
          print(matrix[0][i])

      # matrix diagonalization
      n = 10
      def calculate(x, n):
          tempTensor = x
          for i in range(n - 1):
              x = torch.matmul(tempTensor, x)
          return x
      x = torch.tensor([[3, 1], [0, 2]], dtype=torch.float32)
      eignVector = torch.tensor([[1, -1], [0, 1]], dtype=torch.float32)
      mid = torch.matmul(x, eignVector)
      eigenbasis = torch.matmul(torch.inverse(eignVector), mid)
      transformInThatAxis = calculate(eigenbasis, n)
      print(torch.matmul(eignVector, torch.matmul(transformInThatAxis, torch.inverse(eignVector))))
      print(calculate(x, n))

      # SVD function
      A = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])
      U, S, VT = torch.svd(A)
      print("U:")
      print(U)
      print("S:")
      print(S)
      print("VT:")
      print(VT)

      # Iterator of dataloader and cov trick
      transform = transforms.Compose([
          transforms.ToTensor(),
          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
      ])
      batch_size = 4
      test_dataset = torchvision.datasets.CIFAR10(
          root='./data', train=False, download=True, transform=transform)
      test_loader = torch.utils.data.DataLoader(
          test_dataset, batch_size=batch_size, shuffle=False)
      iterdata = iter(test_loader)
      images, labels = next(iterdata)
      print(images.shape)
      conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)
      feature_map = conv1(images)
      print(feature_map.shape)
    </code>
  </pre>
</body>
</html>
